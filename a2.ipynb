{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faa53c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (window.IPython && IPython.notebook.kernel) IPython.notebook.kernel.execute('jovian.utils.jupyter.get_notebook_name_saved = lambda: \"' + IPython.notebook.notebook_name + '\"')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import jovian\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "project_name='02-insurance-linear-regression'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fae29372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/khaled/datasets/insurance.csv\n"
     ]
    }
   ],
   "source": [
    "DATASET_URL = \"https://gist.github.com/BirajCoder/5f068dfe759c1ea6bdfce9535acdb72d/raw/c84d84e3c80f93be67f6c069cbdc0195ec36acbd/insurance.csv\"\n",
    "DATA_FILEPATH = \"~/datasets/insurance.csv\"\n",
    "download_url(DATASET_URL, '~/datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da0e9974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv(DATA_FILEPATH)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d8dac46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1338 entries, 0 to 1337\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1338 non-null   int64  \n",
      " 1   sex       1338 non-null   object \n",
      " 2   bmi       1338 non-null   float64\n",
      " 3   children  1338 non-null   int64  \n",
      " 4   smoker    1338 non-null   object \n",
      " 5   region    1338 non-null   object \n",
      " 6   charges   1338 non-null   float64\n",
      "dtypes: float64(2), int64(2), object(3)\n",
      "memory usage: 73.3+ KB\n"
     ]
    }
   ],
   "source": [
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31dec2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols=['sex','smoker','region']\n",
    "input_cols = list(dataframe.columns[0:-1])\n",
    "output_cols = list([dataframe.columns[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de4fe9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = len(dataframe)\n",
    "val_percent = 0.2\n",
    "val_size = int(num_rows * val_percent)\n",
    "train_size = num_rows - val_size\n",
    "batch_size = 32\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8221ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_arrays(dataframe):\n",
    "    # Make a copy of the original dataframe\n",
    "    dataframe1 = dataframe.copy(deep=True)\n",
    "    # Convert non-numeric categorical columns to numbers\n",
    "    for col in categorical_cols:\n",
    "        dataframe1[col] = dataframe1[col].astype('category').cat.codes\n",
    "    # Extract input & outupts as numpy arrays\n",
    "    inputs_array = dataframe1[input_cols].to_numpy()\n",
    "    targets_array = dataframe1[output_cols].to_numpy()\n",
    "    return inputs_array, targets_array\n",
    "inputs_array, targets_array = dataframe_to_arrays(dataframe)\n",
    "inputs_array, targets_array\n",
    "\n",
    "\n",
    "inputs = torch.from_numpy(inputs_array).float()\n",
    "targets = torch.from_numpy(targets_array).float()\n",
    "dataset = TensorDataset(inputs, targets)\n",
    "\n",
    "\n",
    "\n",
    "train_ds, val_ds = random_split(dataset, [train_size,val_size])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37a99e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: tensor([[19.0000,  0.0000, 29.8000,  0.0000,  0.0000,  3.0000],\n",
      "        [60.0000,  0.0000, 28.7000,  1.0000,  0.0000,  3.0000],\n",
      "        [32.0000,  1.0000, 33.6300,  1.0000,  1.0000,  0.0000],\n",
      "        [61.0000,  1.0000, 33.5350,  0.0000,  0.0000,  0.0000],\n",
      "        [20.0000,  0.0000, 21.8000,  0.0000,  1.0000,  3.0000],\n",
      "        [50.0000,  0.0000, 30.1150,  1.0000,  0.0000,  1.0000],\n",
      "        [49.0000,  1.0000, 36.8500,  0.0000,  0.0000,  2.0000],\n",
      "        [33.0000,  1.0000, 30.2500,  0.0000,  0.0000,  2.0000],\n",
      "        [43.0000,  0.0000, 32.5600,  3.0000,  1.0000,  2.0000],\n",
      "        [27.0000,  0.0000, 32.3950,  1.0000,  0.0000,  0.0000],\n",
      "        [31.0000,  0.0000, 25.8000,  2.0000,  0.0000,  3.0000],\n",
      "        [18.0000,  1.0000, 23.0850,  0.0000,  0.0000,  0.0000],\n",
      "        [18.0000,  0.0000, 36.8500,  0.0000,  1.0000,  2.0000],\n",
      "        [48.0000,  0.0000, 28.8800,  1.0000,  0.0000,  1.0000],\n",
      "        [35.0000,  1.0000, 24.1300,  1.0000,  0.0000,  1.0000],\n",
      "        [46.0000,  1.0000, 38.1700,  2.0000,  0.0000,  2.0000],\n",
      "        [58.0000,  1.0000, 23.3000,  0.0000,  0.0000,  3.0000],\n",
      "        [53.0000,  0.0000, 33.2500,  0.0000,  0.0000,  0.0000],\n",
      "        [55.0000,  0.0000, 25.3650,  3.0000,  0.0000,  0.0000],\n",
      "        [44.0000,  0.0000, 29.8100,  2.0000,  0.0000,  2.0000],\n",
      "        [35.0000,  0.0000, 34.2100,  1.0000,  0.0000,  2.0000],\n",
      "        [41.0000,  0.0000, 32.6000,  3.0000,  0.0000,  3.0000],\n",
      "        [28.0000,  0.0000, 23.8450,  2.0000,  0.0000,  1.0000],\n",
      "        [31.0000,  1.0000, 28.5950,  1.0000,  0.0000,  1.0000],\n",
      "        [37.0000,  0.0000, 17.2900,  2.0000,  0.0000,  0.0000],\n",
      "        [33.0000,  0.0000, 39.8200,  1.0000,  0.0000,  2.0000],\n",
      "        [20.0000,  0.0000, 24.4200,  0.0000,  1.0000,  2.0000],\n",
      "        [22.0000,  0.0000, 20.2350,  0.0000,  0.0000,  1.0000],\n",
      "        [52.0000,  1.0000, 38.6000,  2.0000,  0.0000,  3.0000],\n",
      "        [47.0000,  1.0000, 38.9400,  2.0000,  1.0000,  2.0000],\n",
      "        [24.0000,  1.0000, 25.8000,  0.0000,  0.0000,  3.0000],\n",
      "        [30.0000,  0.0000, 21.9450,  1.0000,  0.0000,  0.0000]]) len:  32\n",
      "targets: tensor([[ 1744.4650],\n",
      "        [13224.6934],\n",
      "        [37607.5273],\n",
      "        [13143.3369],\n",
      "        [20167.3359],\n",
      "        [ 9910.3594],\n",
      "        [ 8125.7847],\n",
      "        [ 3704.3545],\n",
      "        [40941.2852],\n",
      "        [18903.4922],\n",
      "        [ 4934.7051],\n",
      "        [ 1704.7002],\n",
      "        [36149.4844],\n",
      "        [ 9249.4951],\n",
      "        [ 5125.2158],\n",
      "        [ 8347.1641],\n",
      "        [11345.5186],\n",
      "        [10564.8848],\n",
      "        [13047.3320],\n",
      "        [ 8219.2041],\n",
      "        [ 5245.2271],\n",
      "        [ 7954.5171],\n",
      "        [ 4719.7363],\n",
      "        [ 4243.5898],\n",
      "        [ 6877.9800],\n",
      "        [ 4795.6567],\n",
      "        [26125.6738],\n",
      "        [ 2527.8186],\n",
      "        [10325.2061],\n",
      "        [44202.6523],\n",
      "        [ 1972.9500],\n",
      "        [ 4718.2036]]) len:  32\n"
     ]
    }
   ],
   "source": [
    "#verify data prep is correct\n",
    "for xb, yb in train_loader:\n",
    "    print(\"inputs:\", xb, \"len: \", len(xb))\n",
    "    print(\"targets:\", yb, \"len: \",len(yb))\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c08f436d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.2837,  0.3896,  0.3725,  0.3933, -0.3405,  0.1960]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.1948], requires_grad=True)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn \n",
    "import torch.nn.functional as F\n",
    "\n",
    "input_size = len(input_cols)\n",
    "output_size = len(output_cols)\n",
    "\n",
    "class InsuranceModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)                  # fill this (hint: use input_size & output_size defined above)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        out = self.linear(xb)                          # fill this\n",
    "        return out\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        inputs, targets = batch\n",
    "        # Generate predictions\n",
    "        out = self(inputs)\n",
    "        # Calcuate loss\n",
    "        loss = F.mse_loss(out, targets)                          # fill this\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        inputs, targets = batch\n",
    "        # Generate predictions\n",
    "        out = self(inputs)\n",
    "        # Calculate loss\n",
    "        loss = F.mse_loss(out, targets)                           # fill this    \n",
    "        return {'val_loss': loss.detach()}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        return {'val_loss': epoch_loss.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result, num_epochs):\n",
    "        # Print result every 20th epoch\n",
    "        if (epoch+1) % 100 == 0 or epoch == num_epochs-1:\n",
    "            print(\"Epoch [{}], val_loss: {:.4f}\".format(epoch+1, result['val_loss']))\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "model = InsuranceModel()\n",
    "list(model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6f0e1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        for batch in train_loader:\n",
    "            inputs, targets = batch\n",
    "            loss = model.training_step(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        model.epoch_end(epoch, result, epochs)\n",
    "        history.append(result)\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3848f228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': 304040864.0}\n"
     ]
    }
   ],
   "source": [
    "result = evaluate(model,val_loader) # Use the the evaluate function\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd4ab05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100], val_loss: 123027880.0000\n",
      "Epoch [200], val_loss: 121043328.0000\n",
      "Epoch [300], val_loss: 119309096.0000\n",
      "Epoch [400], val_loss: 117799768.0000\n",
      "Epoch [500], val_loss: 116218768.0000\n",
      "Epoch [600], val_loss: 114475376.0000\n",
      "Epoch [700], val_loss: 113269792.0000\n",
      "Epoch [800], val_loss: 111497200.0000\n",
      "Epoch [900], val_loss: 110202832.0000\n",
      "Epoch [1000], val_loss: 108760160.0000\n",
      "Epoch [1100], val_loss: 107432952.0000\n",
      "Epoch [1200], val_loss: 106093632.0000\n",
      "Epoch [1300], val_loss: 104948832.0000\n",
      "Epoch [1400], val_loss: 103481504.0000\n",
      "Epoch [1500], val_loss: 102250744.0000\n",
      "Epoch [1600], val_loss: 101165344.0000\n",
      "Epoch [1700], val_loss: 100017824.0000\n",
      "Epoch [1800], val_loss: 98820440.0000\n",
      "Epoch [1900], val_loss: 97557600.0000\n",
      "Epoch [2000], val_loss: 96498240.0000\n",
      "Epoch [2100], val_loss: 95426248.0000\n",
      "Epoch [2200], val_loss: 94403528.0000\n",
      "Epoch [2300], val_loss: 93351984.0000\n",
      "Epoch [2400], val_loss: 92269480.0000\n",
      "Epoch [2500], val_loss: 91210776.0000\n",
      "Epoch [2600], val_loss: 90334960.0000\n",
      "Epoch [2700], val_loss: 89392416.0000\n",
      "Epoch [2800], val_loss: 88372704.0000\n",
      "Epoch [2900], val_loss: 87476456.0000\n",
      "Epoch [3000], val_loss: 86618368.0000\n",
      "Epoch [3100], val_loss: 85706160.0000\n",
      "Epoch [3200], val_loss: 85050120.0000\n",
      "Epoch [3300], val_loss: 84051032.0000\n",
      "Epoch [3400], val_loss: 83192000.0000\n",
      "Epoch [3500], val_loss: 82418320.0000\n",
      "Epoch [3600], val_loss: 81562848.0000\n",
      "Epoch [3700], val_loss: 80841528.0000\n",
      "Epoch [3800], val_loss: 80050144.0000\n",
      "Epoch [3900], val_loss: 79332608.0000\n",
      "Epoch [4000], val_loss: 78663584.0000\n",
      "Epoch [4100], val_loss: 77917736.0000\n",
      "Epoch [4200], val_loss: 77222176.0000\n",
      "Epoch [4300], val_loss: 76631552.0000\n",
      "Epoch [4400], val_loss: 75889392.0000\n",
      "Epoch [4500], val_loss: 75202688.0000\n",
      "Epoch [4600], val_loss: 74596000.0000\n",
      "Epoch [4700], val_loss: 73981488.0000\n",
      "Epoch [4800], val_loss: 73391376.0000\n",
      "Epoch [4900], val_loss: 72755112.0000\n",
      "Epoch [5000], val_loss: 72208528.0000\n",
      "Epoch [5100], val_loss: 71608864.0000\n",
      "Epoch [5200], val_loss: 71049392.0000\n",
      "Epoch [5300], val_loss: 70497528.0000\n",
      "Epoch [5400], val_loss: 69980760.0000\n",
      "Epoch [5500], val_loss: 69436920.0000\n",
      "Epoch [5600], val_loss: 68949688.0000\n",
      "Epoch [5700], val_loss: 68566968.0000\n",
      "Epoch [5800], val_loss: 67944456.0000\n",
      "Epoch [5900], val_loss: 67427048.0000\n",
      "Epoch [6000], val_loss: 66978452.0000\n",
      "Epoch [6100], val_loss: 66513168.0000\n",
      "Epoch [6200], val_loss: 66081144.0000\n",
      "Epoch [6300], val_loss: 65650416.0000\n",
      "Epoch [6400], val_loss: 65190052.0000\n",
      "Epoch [6500], val_loss: 64768036.0000\n",
      "Epoch [6600], val_loss: 64382648.0000\n",
      "Epoch [6700], val_loss: 63935744.0000\n",
      "Epoch [6800], val_loss: 63561644.0000\n",
      "Epoch [6900], val_loss: 63230064.0000\n",
      "Epoch [7000], val_loss: 62762260.0000\n",
      "Epoch [7100], val_loss: 62418576.0000\n",
      "Epoch [7200], val_loss: 62011848.0000\n",
      "Epoch [7300], val_loss: 61695792.0000\n",
      "Epoch [7400], val_loss: 61306796.0000\n",
      "Epoch [7500], val_loss: 60972816.0000\n",
      "Epoch [7600], val_loss: 60644752.0000\n",
      "Epoch [7700], val_loss: 60283440.0000\n",
      "Epoch [7800], val_loss: 60000812.0000\n",
      "Epoch [7900], val_loss: 59655852.0000\n",
      "Epoch [8000], val_loss: 59351060.0000\n",
      "Epoch [8100], val_loss: 59024824.0000\n",
      "Epoch [8200], val_loss: 58916480.0000\n",
      "Epoch [8300], val_loss: 58417284.0000\n",
      "Epoch [8400], val_loss: 58140240.0000\n",
      "Epoch [8500], val_loss: 57887140.0000\n",
      "Epoch [8600], val_loss: 57589100.0000\n",
      "Epoch [8700], val_loss: 57428188.0000\n",
      "Epoch [8800], val_loss: 57102064.0000\n",
      "Epoch [8900], val_loss: 56819648.0000\n",
      "Epoch [9000], val_loss: 56569508.0000\n",
      "Epoch [9100], val_loss: 56336896.0000\n",
      "Epoch [9200], val_loss: 56045928.0000\n",
      "Epoch [9300], val_loss: 55963336.0000\n",
      "Epoch [9400], val_loss: 55671408.0000\n",
      "Epoch [9500], val_loss: 55405080.0000\n",
      "Epoch [9600], val_loss: 55178604.0000\n",
      "Epoch [9700], val_loss: 54907700.0000\n",
      "Epoch [9800], val_loss: 54736880.0000\n",
      "Epoch [9900], val_loss: 54535604.0000\n",
      "Epoch [10000], val_loss: 54345432.0000\n",
      "Epoch [10100], val_loss: 54060044.0000\n",
      "Epoch [10200], val_loss: 53875844.0000\n",
      "Epoch [10300], val_loss: 53675560.0000\n",
      "Epoch [10400], val_loss: 53446092.0000\n",
      "Epoch [10500], val_loss: 53380384.0000\n",
      "Epoch [10600], val_loss: 53086820.0000\n",
      "Epoch [10700], val_loss: 52919540.0000\n",
      "Epoch [10800], val_loss: 52799212.0000\n",
      "Epoch [10900], val_loss: 52625300.0000\n",
      "Epoch [11000], val_loss: 52460032.0000\n",
      "Epoch [11100], val_loss: 52379728.0000\n",
      "Epoch [11200], val_loss: 52220104.0000\n",
      "Epoch [11300], val_loss: 52089040.0000\n",
      "Epoch [11400], val_loss: 51792812.0000\n",
      "Epoch [11500], val_loss: 51764720.0000\n",
      "Epoch [11600], val_loss: 51513600.0000\n",
      "Epoch [11700], val_loss: 51318680.0000\n",
      "Epoch [11800], val_loss: 51181544.0000\n",
      "Epoch [11900], val_loss: 51042420.0000\n",
      "Epoch [12000], val_loss: 50879620.0000\n",
      "Epoch [12100], val_loss: 50855152.0000\n",
      "Epoch [12200], val_loss: 50835400.0000\n",
      "Epoch [12300], val_loss: 50454312.0000\n",
      "Epoch [12400], val_loss: 50562448.0000\n",
      "Epoch [12500], val_loss: 50284332.0000\n",
      "Epoch [12600], val_loss: 50202852.0000\n",
      "Epoch [12700], val_loss: 50023896.0000\n",
      "Epoch [12800], val_loss: 49863888.0000\n",
      "Epoch [12900], val_loss: 49922852.0000\n",
      "Epoch [13000], val_loss: 49621136.0000\n",
      "Epoch [13100], val_loss: 49646960.0000\n",
      "Epoch [13200], val_loss: 49448464.0000\n",
      "Epoch [13300], val_loss: 49235056.0000\n",
      "Epoch [13400], val_loss: 49209060.0000\n",
      "Epoch [13500], val_loss: 49146880.0000\n",
      "Epoch [13600], val_loss: 49059116.0000\n",
      "Epoch [13700], val_loss: 48917440.0000\n",
      "Epoch [13800], val_loss: 48701968.0000\n",
      "Epoch [13900], val_loss: 48672120.0000\n",
      "Epoch [14000], val_loss: 48567228.0000\n",
      "Epoch [14100], val_loss: 48539864.0000\n",
      "Epoch [14200], val_loss: 48497936.0000\n",
      "Epoch [14300], val_loss: 48342516.0000\n",
      "Epoch [14400], val_loss: 48202424.0000\n",
      "Epoch [14500], val_loss: 48190020.0000\n",
      "Epoch [14600], val_loss: 48116880.0000\n",
      "Epoch [14700], val_loss: 48026248.0000\n",
      "Epoch [14800], val_loss: 47814352.0000\n",
      "Epoch [14900], val_loss: 47839340.0000\n",
      "Epoch [15000], val_loss: 47752024.0000\n",
      "Epoch [15100], val_loss: 47520400.0000\n",
      "Epoch [15200], val_loss: 47573212.0000\n",
      "Epoch [15300], val_loss: 47582956.0000\n",
      "Epoch [15400], val_loss: 47499020.0000\n",
      "Epoch [15500], val_loss: 47287976.0000\n",
      "Epoch [15600], val_loss: 47215816.0000\n",
      "Epoch [15700], val_loss: 47380032.0000\n",
      "Epoch [15800], val_loss: 47205064.0000\n",
      "Epoch [15900], val_loss: 47102860.0000\n",
      "Epoch [16000], val_loss: 47259008.0000\n",
      "Epoch [16100], val_loss: 46948604.0000\n",
      "Epoch [16200], val_loss: 47007796.0000\n",
      "Epoch [16300], val_loss: 46796320.0000\n",
      "Epoch [16400], val_loss: 46708272.0000\n",
      "Epoch [16500], val_loss: 46567888.0000\n",
      "Epoch [16600], val_loss: 46839484.0000\n",
      "Epoch [16700], val_loss: 46677288.0000\n",
      "Epoch [16800], val_loss: 46540844.0000\n",
      "Epoch [16900], val_loss: 46558480.0000\n",
      "Epoch [17000], val_loss: 46360936.0000\n",
      "Epoch [17100], val_loss: 46533916.0000\n",
      "Epoch [17200], val_loss: 46287432.0000\n",
      "Epoch [17300], val_loss: 46326268.0000\n",
      "Epoch [17400], val_loss: 46159008.0000\n",
      "Epoch [17500], val_loss: 46051500.0000\n",
      "Epoch [17600], val_loss: 46043644.0000\n",
      "Epoch [17700], val_loss: 45982528.0000\n",
      "Epoch [17800], val_loss: 46120496.0000\n",
      "Epoch [17900], val_loss: 45977536.0000\n",
      "Epoch [18000], val_loss: 45745484.0000\n",
      "Epoch [18100], val_loss: 45805956.0000\n",
      "Epoch [18200], val_loss: 45813488.0000\n",
      "Epoch [18300], val_loss: 45650224.0000\n",
      "Epoch [18400], val_loss: 45727552.0000\n",
      "Epoch [18500], val_loss: 45778292.0000\n",
      "Epoch [18600], val_loss: 45767100.0000\n",
      "Epoch [18700], val_loss: 45527340.0000\n",
      "Epoch [18800], val_loss: 45410204.0000\n",
      "Epoch [18900], val_loss: 45501812.0000\n",
      "Epoch [19000], val_loss: 45378380.0000\n",
      "Epoch [19100], val_loss: 45381724.0000\n",
      "Epoch [19200], val_loss: 45311040.0000\n",
      "Epoch [19300], val_loss: 45274748.0000\n",
      "Epoch [19400], val_loss: 45230820.0000\n",
      "Epoch [19500], val_loss: 45301744.0000\n",
      "Epoch [19600], val_loss: 45276664.0000\n",
      "Epoch [19700], val_loss: 45305204.0000\n",
      "Epoch [19800], val_loss: 45048624.0000\n",
      "Epoch [19900], val_loss: 45088204.0000\n",
      "Epoch [20000], val_loss: 45280708.0000\n",
      "Epoch [20100], val_loss: 45297760.0000\n",
      "Epoch [20200], val_loss: 45138808.0000\n",
      "Epoch [20300], val_loss: 45130720.0000\n",
      "Epoch [20400], val_loss: 44999756.0000\n",
      "Epoch [20500], val_loss: 44747332.0000\n",
      "Epoch [20600], val_loss: 44724404.0000\n",
      "Epoch [20700], val_loss: 44700548.0000\n",
      "Epoch [20800], val_loss: 44779920.0000\n",
      "Epoch [20900], val_loss: 44914704.0000\n",
      "Epoch [21000], val_loss: 44660940.0000\n",
      "Epoch [21100], val_loss: 44664404.0000\n",
      "Epoch [21200], val_loss: 44638652.0000\n",
      "Epoch [21300], val_loss: 44713616.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21400], val_loss: 44615428.0000\n",
      "Epoch [21500], val_loss: 44643820.0000\n",
      "Epoch [21600], val_loss: 44475952.0000\n",
      "Epoch [21700], val_loss: 44412868.0000\n",
      "Epoch [21800], val_loss: 44752552.0000\n",
      "Epoch [21900], val_loss: 44628628.0000\n",
      "Epoch [22000], val_loss: 44483124.0000\n",
      "Epoch [22100], val_loss: 44366372.0000\n",
      "Epoch [22200], val_loss: 44476388.0000\n",
      "Epoch [22300], val_loss: 44574744.0000\n",
      "Epoch [22400], val_loss: 44358384.0000\n",
      "Epoch [22500], val_loss: 44354448.0000\n",
      "Epoch [22600], val_loss: 44364664.0000\n",
      "Epoch [22700], val_loss: 44236964.0000\n",
      "Epoch [22800], val_loss: 44406896.0000\n",
      "Epoch [22900], val_loss: 44536976.0000\n",
      "Epoch [23000], val_loss: 44242316.0000\n",
      "Epoch [23100], val_loss: 44413688.0000\n",
      "Epoch [23200], val_loss: 44215792.0000\n",
      "Epoch [23300], val_loss: 44305812.0000\n",
      "Epoch [23400], val_loss: 44105532.0000\n",
      "Epoch [23500], val_loss: 44320700.0000\n",
      "Epoch [23600], val_loss: 44141008.0000\n",
      "Epoch [23700], val_loss: 44045708.0000\n",
      "Epoch [23800], val_loss: 44267632.0000\n",
      "Epoch [23900], val_loss: 44025864.0000\n",
      "Epoch [24000], val_loss: 43875540.0000\n",
      "Epoch [24100], val_loss: 43984112.0000\n",
      "Epoch [24200], val_loss: 44125592.0000\n",
      "Epoch [24300], val_loss: 43944752.0000\n",
      "Epoch [24400], val_loss: 43752708.0000\n",
      "Epoch [24500], val_loss: 43876216.0000\n",
      "Epoch [24600], val_loss: 43866804.0000\n",
      "Epoch [24700], val_loss: 43763548.0000\n",
      "Epoch [24800], val_loss: 43835692.0000\n",
      "Epoch [24900], val_loss: 43806128.0000\n",
      "Epoch [25000], val_loss: 43953352.0000\n",
      "Epoch [25100], val_loss: 43843132.0000\n",
      "Epoch [25200], val_loss: 43771312.0000\n",
      "Epoch [25300], val_loss: 43938036.0000\n",
      "Epoch [25400], val_loss: 44047936.0000\n",
      "Epoch [25500], val_loss: 43795716.0000\n",
      "Epoch [25600], val_loss: 43677056.0000\n",
      "Epoch [25700], val_loss: 43742576.0000\n",
      "Epoch [25800], val_loss: 43569728.0000\n",
      "Epoch [25900], val_loss: 43659044.0000\n",
      "Epoch [26000], val_loss: 43594788.0000\n",
      "Epoch [26100], val_loss: 43706736.0000\n",
      "Epoch [26200], val_loss: 43665856.0000\n",
      "Epoch [26300], val_loss: 43831768.0000\n",
      "Epoch [26400], val_loss: 43688884.0000\n",
      "Epoch [26500], val_loss: 43727780.0000\n",
      "Epoch [26600], val_loss: 43838304.0000\n",
      "Epoch [26700], val_loss: 43755288.0000\n",
      "Epoch [26800], val_loss: 43512904.0000\n",
      "Epoch [26900], val_loss: 43560492.0000\n",
      "Epoch [27000], val_loss: 43662968.0000\n",
      "Epoch [27100], val_loss: 43589132.0000\n",
      "Epoch [27200], val_loss: 43366640.0000\n",
      "Epoch [27300], val_loss: 43293488.0000\n",
      "Epoch [27400], val_loss: 43422344.0000\n",
      "Epoch [27500], val_loss: 43285680.0000\n",
      "Epoch [27600], val_loss: 43463564.0000\n",
      "Epoch [27700], val_loss: 43503708.0000\n",
      "Epoch [27800], val_loss: 43194736.0000\n",
      "Epoch [27900], val_loss: 43428264.0000\n",
      "Epoch [28000], val_loss: 43639432.0000\n",
      "Epoch [28100], val_loss: 43308192.0000\n",
      "Epoch [28200], val_loss: 43590560.0000\n",
      "Epoch [28300], val_loss: 43429724.0000\n",
      "Epoch [28400], val_loss: 43373864.0000\n",
      "Epoch [28500], val_loss: 43367408.0000\n",
      "Epoch [28600], val_loss: 43385000.0000\n",
      "Epoch [28700], val_loss: 43292104.0000\n",
      "Epoch [28800], val_loss: 43375928.0000\n",
      "Epoch [28900], val_loss: 43315452.0000\n",
      "Epoch [29000], val_loss: 43292116.0000\n",
      "Epoch [29100], val_loss: 43317048.0000\n",
      "Epoch [29200], val_loss: 43266120.0000\n",
      "Epoch [29300], val_loss: 43200888.0000\n",
      "Epoch [29400], val_loss: 43174728.0000\n",
      "Epoch [29500], val_loss: 43276816.0000\n",
      "Epoch [29600], val_loss: 43217976.0000\n",
      "Epoch [29700], val_loss: 43274808.0000\n",
      "Epoch [29800], val_loss: 43418700.0000\n",
      "Epoch [29900], val_loss: 43153220.0000\n",
      "Epoch [30000], val_loss: 43287652.0000\n",
      "Epoch [30100], val_loss: 43380760.0000\n",
      "Epoch [30200], val_loss: 43423984.0000\n",
      "Epoch [30300], val_loss: 43026368.0000\n",
      "Epoch [30400], val_loss: 42976208.0000\n",
      "Epoch [30500], val_loss: 42991376.0000\n",
      "Epoch [30600], val_loss: 43243392.0000\n",
      "Epoch [30700], val_loss: 42918308.0000\n",
      "Epoch [30800], val_loss: 43140516.0000\n",
      "Epoch [30900], val_loss: 43409648.0000\n",
      "Epoch [31000], val_loss: 43024540.0000\n",
      "Epoch [31100], val_loss: 42954596.0000\n",
      "Epoch [31200], val_loss: 43258432.0000\n",
      "Epoch [31300], val_loss: 42911632.0000\n",
      "Epoch [31400], val_loss: 43109564.0000\n",
      "Epoch [31500], val_loss: 43024512.0000\n",
      "Epoch [31600], val_loss: 43041584.0000\n",
      "Epoch [31700], val_loss: 43153936.0000\n",
      "Epoch [31800], val_loss: 43029064.0000\n",
      "Epoch [31900], val_loss: 43111508.0000\n",
      "Epoch [32000], val_loss: 43145380.0000\n",
      "Epoch [32100], val_loss: 43000848.0000\n",
      "Epoch [32200], val_loss: 43105164.0000\n",
      "Epoch [32300], val_loss: 43045436.0000\n",
      "Epoch [32400], val_loss: 43043152.0000\n",
      "Epoch [32500], val_loss: 43004144.0000\n",
      "Epoch [32600], val_loss: 42758776.0000\n",
      "Epoch [32700], val_loss: 42971600.0000\n",
      "Epoch [32800], val_loss: 42886568.0000\n",
      "Epoch [32900], val_loss: 42860672.0000\n",
      "Epoch [33000], val_loss: 43045016.0000\n",
      "Epoch [33100], val_loss: 42925344.0000\n",
      "Epoch [33200], val_loss: 42865364.0000\n",
      "Epoch [33300], val_loss: 42857500.0000\n",
      "Epoch [33400], val_loss: 42894076.0000\n",
      "Epoch [33500], val_loss: 42823212.0000\n",
      "Epoch [33600], val_loss: 42865564.0000\n",
      "Epoch [33700], val_loss: 42779376.0000\n",
      "Epoch [33800], val_loss: 42939968.0000\n",
      "Epoch [33900], val_loss: 43106012.0000\n",
      "Epoch [34000], val_loss: 42780560.0000\n",
      "Epoch [34100], val_loss: 42997304.0000\n",
      "Epoch [34200], val_loss: 42797744.0000\n",
      "Epoch [34300], val_loss: 42708324.0000\n",
      "Epoch [34400], val_loss: 42969424.0000\n",
      "Epoch [34500], val_loss: 42709648.0000\n",
      "Epoch [34600], val_loss: 42680976.0000\n",
      "Epoch [34700], val_loss: 42673876.0000\n",
      "Epoch [34800], val_loss: 42719128.0000\n",
      "Epoch [34900], val_loss: 42850140.0000\n",
      "Epoch [35000], val_loss: 42798028.0000\n",
      "Epoch [35100], val_loss: 42809252.0000\n",
      "Epoch [35200], val_loss: 42621092.0000\n",
      "Epoch [35300], val_loss: 42716180.0000\n",
      "Epoch [35400], val_loss: 42721584.0000\n",
      "Epoch [35500], val_loss: 42744304.0000\n",
      "Epoch [35600], val_loss: 42734512.0000\n",
      "Epoch [35700], val_loss: 42755680.0000\n",
      "Epoch [35800], val_loss: 42792464.0000\n",
      "Epoch [35900], val_loss: 42707164.0000\n",
      "Epoch [36000], val_loss: 42666136.0000\n",
      "Epoch [36100], val_loss: 42604208.0000\n",
      "Epoch [36200], val_loss: 42790416.0000\n",
      "Epoch [36300], val_loss: 42699128.0000\n",
      "Epoch [36400], val_loss: 42559488.0000\n",
      "Epoch [36500], val_loss: 42444592.0000\n",
      "Epoch [36600], val_loss: 42730780.0000\n",
      "Epoch [36700], val_loss: 42590576.0000\n",
      "Epoch [36800], val_loss: 42700220.0000\n",
      "Epoch [36900], val_loss: 42924284.0000\n",
      "Epoch [37000], val_loss: 42425704.0000\n",
      "Epoch [37100], val_loss: 42474192.0000\n",
      "Epoch [37200], val_loss: 42481980.0000\n",
      "Epoch [37300], val_loss: 42389500.0000\n",
      "Epoch [37400], val_loss: 42857932.0000\n",
      "Epoch [37500], val_loss: 42577348.0000\n",
      "Epoch [37600], val_loss: 42647048.0000\n",
      "Epoch [37700], val_loss: 42825320.0000\n",
      "Epoch [37800], val_loss: 42477344.0000\n",
      "Epoch [37900], val_loss: 42730708.0000\n",
      "Epoch [38000], val_loss: 42554780.0000\n",
      "Epoch [38100], val_loss: 42758364.0000\n",
      "Epoch [38200], val_loss: 42474992.0000\n",
      "Epoch [38300], val_loss: 42830488.0000\n",
      "Epoch [38400], val_loss: 42446908.0000\n",
      "Epoch [38500], val_loss: 42459392.0000\n",
      "Epoch [38600], val_loss: 42849232.0000\n",
      "Epoch [38700], val_loss: 42498456.0000\n",
      "Epoch [38800], val_loss: 42863796.0000\n",
      "Epoch [38900], val_loss: 42437700.0000\n",
      "Epoch [39000], val_loss: 42534196.0000\n",
      "Epoch [39100], val_loss: 42615608.0000\n",
      "Epoch [39200], val_loss: 42669916.0000\n",
      "Epoch [39300], val_loss: 42419068.0000\n",
      "Epoch [39400], val_loss: 42510608.0000\n",
      "Epoch [39500], val_loss: 42671624.0000\n",
      "Epoch [39600], val_loss: 42624012.0000\n",
      "Epoch [39700], val_loss: 42422648.0000\n",
      "Epoch [39800], val_loss: 42453452.0000\n",
      "Epoch [39900], val_loss: 42595280.0000\n",
      "Epoch [40000], val_loss: 42511916.0000\n",
      "Epoch [40100], val_loss: 42351304.0000\n",
      "Epoch [40200], val_loss: 42504032.0000\n",
      "Epoch [40300], val_loss: 42309376.0000\n",
      "Epoch [40400], val_loss: 42421740.0000\n",
      "Epoch [40500], val_loss: 42563252.0000\n",
      "Epoch [40600], val_loss: 42334672.0000\n",
      "Epoch [40700], val_loss: 42231824.0000\n",
      "Epoch [40800], val_loss: 42656352.0000\n",
      "Epoch [40900], val_loss: 42426624.0000\n",
      "Epoch [41000], val_loss: 42564544.0000\n",
      "Epoch [41100], val_loss: 42534556.0000\n",
      "Epoch [41200], val_loss: 42479160.0000\n",
      "Epoch [41300], val_loss: 42371504.0000\n",
      "Epoch [41400], val_loss: 42467860.0000\n",
      "Epoch [41500], val_loss: 42325688.0000\n",
      "Epoch [41600], val_loss: 42481496.0000\n",
      "Epoch [41700], val_loss: 42792676.0000\n",
      "Epoch [41800], val_loss: 42556552.0000\n",
      "Epoch [41900], val_loss: 42489056.0000\n",
      "Epoch [42000], val_loss: 42519736.0000\n",
      "Epoch [42100], val_loss: 42395920.0000\n",
      "Epoch [42200], val_loss: 42410408.0000\n",
      "Epoch [42300], val_loss: 42226312.0000\n",
      "Epoch [42400], val_loss: 42429028.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42500], val_loss: 42368120.0000\n",
      "Epoch [42600], val_loss: 42296360.0000\n",
      "Epoch [42700], val_loss: 42472900.0000\n",
      "Epoch [42800], val_loss: 42464900.0000\n",
      "Epoch [42900], val_loss: 42368832.0000\n",
      "Epoch [43000], val_loss: 42238912.0000\n",
      "Epoch [43100], val_loss: 42188124.0000\n",
      "Epoch [43200], val_loss: 42581456.0000\n",
      "Epoch [43300], val_loss: 42054036.0000\n",
      "Epoch [43400], val_loss: 42375360.0000\n",
      "Epoch [43500], val_loss: 42426544.0000\n",
      "Epoch [43600], val_loss: 42088416.0000\n",
      "Epoch [43700], val_loss: 42342620.0000\n",
      "Epoch [43800], val_loss: 42518320.0000\n",
      "Epoch [43900], val_loss: 42239924.0000\n",
      "Epoch [44000], val_loss: 42218864.0000\n",
      "Epoch [44100], val_loss: 42260560.0000\n",
      "Epoch [44200], val_loss: 42421852.0000\n",
      "Epoch [44300], val_loss: 42548688.0000\n",
      "Epoch [44400], val_loss: 42405220.0000\n",
      "Epoch [44500], val_loss: 42622264.0000\n",
      "Epoch [44600], val_loss: 42258864.0000\n",
      "Epoch [44700], val_loss: 42188856.0000\n",
      "Epoch [44800], val_loss: 42263240.0000\n",
      "Epoch [44900], val_loss: 42288980.0000\n",
      "Epoch [45000], val_loss: 41940320.0000\n",
      "Epoch [45100], val_loss: 42173980.0000\n",
      "Epoch [45200], val_loss: 42074540.0000\n",
      "Epoch [45300], val_loss: 42361948.0000\n",
      "Epoch [45400], val_loss: 42141164.0000\n",
      "Epoch [45500], val_loss: 42361152.0000\n",
      "Epoch [45600], val_loss: 42251864.0000\n",
      "Epoch [45700], val_loss: 42219552.0000\n",
      "Epoch [45800], val_loss: 42281412.0000\n",
      "Epoch [45900], val_loss: 42081692.0000\n",
      "Epoch [46000], val_loss: 42431120.0000\n",
      "Epoch [46100], val_loss: 42165480.0000\n",
      "Epoch [46200], val_loss: 42001112.0000\n",
      "Epoch [46300], val_loss: 42395256.0000\n",
      "Epoch [46400], val_loss: 42187884.0000\n",
      "Epoch [46500], val_loss: 42176112.0000\n",
      "Epoch [46600], val_loss: 42071832.0000\n",
      "Epoch [46700], val_loss: 42118308.0000\n",
      "Epoch [46800], val_loss: 42188240.0000\n",
      "Epoch [46900], val_loss: 42121572.0000\n",
      "Epoch [47000], val_loss: 42166128.0000\n",
      "Epoch [47100], val_loss: 42120656.0000\n",
      "Epoch [47200], val_loss: 42200440.0000\n",
      "Epoch [47300], val_loss: 42169992.0000\n",
      "Epoch [47400], val_loss: 42252604.0000\n",
      "Epoch [47500], val_loss: 42032112.0000\n",
      "Epoch [47600], val_loss: 42048528.0000\n",
      "Epoch [47700], val_loss: 42122664.0000\n",
      "Epoch [47800], val_loss: 42372456.0000\n",
      "Epoch [47900], val_loss: 42063500.0000\n",
      "Epoch [48000], val_loss: 41960424.0000\n",
      "Epoch [48100], val_loss: 41972464.0000\n",
      "Epoch [48200], val_loss: 42288956.0000\n",
      "Epoch [48300], val_loss: 41993424.0000\n",
      "Epoch [48400], val_loss: 41957200.0000\n",
      "Epoch [48500], val_loss: 42288452.0000\n",
      "Epoch [48600], val_loss: 42031100.0000\n",
      "Epoch [48700], val_loss: 42166000.0000\n",
      "Epoch [48800], val_loss: 42071696.0000\n",
      "Epoch [48900], val_loss: 41967536.0000\n",
      "Epoch [49000], val_loss: 42070096.0000\n",
      "Epoch [49100], val_loss: 42225660.0000\n",
      "Epoch [49200], val_loss: 42108128.0000\n",
      "Epoch [49300], val_loss: 42104952.0000\n",
      "Epoch [49400], val_loss: 41856008.0000\n",
      "Epoch [49500], val_loss: 42058916.0000\n",
      "Epoch [49600], val_loss: 42162732.0000\n",
      "Epoch [49700], val_loss: 42177060.0000\n",
      "Epoch [49800], val_loss: 42112248.0000\n",
      "Epoch [49900], val_loss: 42151640.0000\n",
      "Epoch [50000], val_loss: 42055376.0000\n"
     ]
    }
   ],
   "source": [
    "history = fit(10000, 1e-5, model, train_loader, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a577b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAdzUlEQVR4nO3deZxcZZ3v8c+XJCSELCzdICSBkLCJ3oDQIuJCxLlDAiiD48KmhCtyo8LoFV8SEASZcYxz1VGvS8xlAEUJi6IgIewm6OUyocMSCSSSxCBtxCTsBCNZfvPHOR0qleru6uXUqarzfb9e/eqqU6eqf0910t96nuec5ygiMDOz4toh7wLMzCxfDgIzs4JzEJiZFZyDwMys4BwEZmYF5yAwMys4B4ENKEmrJP1d3nU0Ikl7SrpP0suSvpF3PeDfZ1E4CMxKSLpMUkj6UMm2wem28Rn/+HOAdcCoiDg/459ltpWDwGx7zwGXSxpU45+7L/B4+CxPqzEHgWVG0lBJ35K0Ov36lqSh6WMtkm6V9IKk5yT9RtIO6WMXSPpTOkSyTNJ7K7z2UZKeKf1jLelkSYvT20dKapf0kqS/SPpmL0q/HXgNOKOLdo2W9GNJayU9JeniztqreE+OlvSgpBfT70en268GzgS+IOmVSsMx6fv5dUl/TNs0S9JO6WOTJXVIukjSunRI5/Rqa5b0CUlPpO/545IOL/nRh0lanNZ8vaRh6XO6/B1aY/EvzbL0ReAo4DDgUOBI4OL0sfOBDqAV2BO4CAhJBwHnAm+NiJHAccCq8heOiAeA9cCxJZtPA65Nb38b+HZEjAImAjf0ou4ALgEulTSkwuP/BxgNTACOAT4GnNXTi0raDZgLfAfYHfgmMFfS7hExDfgp8G8RMSIi7q7wEl8DDiR5P/cHxgBfKnn8DUBLuv1MYHb6fnZbczoMdlm6bRTwfuDZktf9MDAF2A+YBExLt1f8Hfb0Plj9acggkHSlpDWSHqti330k/VrSw+mnmuNrUaMBcDpweUSsiYi1wJeBj6aPbQT2AvaNiI0R8Zt0SGQzMBQ4RNKQiFgVESu6eP05wKkAkkYCx6fbOl9/f0ktEfFKGhxVi4hbgLXA2aXb0x7IR4ALI+LliFgFfKOkXd05AXgyIq6JiE0RMQdYCryvpydKEvAJ4H9FxHMR8TLwr8ApZbteEhF/i4gFJKHz4SpqPpskgB6MxPKIeKrkNb8TEasj4jngVyRBBF3/Dq3BNGQQAFeTfEKpxsXADRHxFpL/NN/Pqijbzt5A6R+Up9JtAP8bWA7cKWmlpBkAEbEc+CzJJ9Q1kq6TtDeVXQt8IB1u+gDwUMkfsI+TfHpemg7BnNiH+i8m6dUMK9nWAuxYoV1jqni98vejN89tBYYDi9KhmBdIhrBaS/Z5PiLWl7323lXUPA7oKmwBnim5/SowIr1d8XdojachgyAi7iOZ0NtK0kRJt0talI5VHty5O0l3F5Ku8eoallp0q0kmQDvtk24j/WR6fkRMIPlE/LnOuYCIuDYi3pk+N0iGRLYTEY+T/EGbyrbDQkTEkxFxKrBH+vyfSdq5N8VHxF0kf+g+VbJ5Hckn4fJ2/amKlyx/P3rz3HXAX4E3RcQu6dfoiBhRss+uZW3sfL97qvlpkuGzXunud2iNpSGDoAuzgfMi4gjg87z+yf8y4AxJHcBtwHn5lFdIc4CLJbVKaiEZz/4JgKQTJe2fDnm8RDIktFnSQZKOTT/lbyD547e5m59xLfBPwLuBGzs3SjpDUmtEbAFeSDd39zpd+SLwhc47EbGZZL7hK5JGStoX+Fxnu3pwG3CgpNOUHJL6EeAQ4Naenpi24/8C/y5pDwBJYyQdV7brlyXtKOldwInAjVXUfAXweUlHKLF/uk+3uvodVvE+WJ1piiCQNAI4GrhR0iPAD0nGLiEZQ746IsaSjCFf4yMbauZfgHZgMfA74KF0G8ABwN3AK8D/B74fEfNJ5gdmknyKfYbkE/1F3fyMOcBk4N6IWFeyfQqwRNIrJBPHp0TEBoD0qJx3VdOAiPh/wMKyzeeRTFSvBH5LEkZXpq99kaR5XbzWsyR/nM8nmYz9AnBiWd3duYCkh/KApJdI3r+DSh5/BniepBfwU2B6RCztqeaIuBH4SrrtZeCXwG5V1NPV79AajBp1bkfJyT23RsSbJY0ClkXEXhX2WwJMiYin0/srgaMiYk1NCzbLkKTJwE/SDzxmvdIUn4wj4iXgD+lhcKTd20PTh/8IvDfd/kaSib+1uRRqZlaHGjIIJM0h6YoelJ5E83GSQxU/LulRYAlwUrr7+cAn0u1zgGk+xM3M7HUNOzRkZmYDoyF7BGZmNnAG511Ab7W0tMT48ePzLsPMrKEsWrRoXUS0Vnqs4YJg/PjxtLe3512GmVlDkVR+VvtWHhoyMys4B4GZWcE5CMzMCs5BYGZWcA4CM7OCa/ogmLVgBfev2HZNr/tXrGPWgu6WXzczK46mD4JJY0dz7rUPbw2D+1es49xrH2bS2NE5V2ZmVh8a7jyC3jp6YgvfPe0tfPInD3HgniN4cs0rfP/0wzl6YkvepZmZ1YWm7xFAEgZHT9ydB1c9z/H/bS+HgJlZiUIEwf0r1vGbJ5OhoVsXr95uzsDMrMiaPgg65wTOefcEAGZMOXibOQMzs6Jr+iCYfd9K/vraJu554hkA3jxmNJ+cPIHzrn2Iwy+/M+fqzMzy1/STxfOXJRcje7TjpeT70y/wlblLu3uKmVmhNH2PQGX3L7l5SS51mJnVq6YPgtPeNi7vEszM6lrTB8FXTp6UdwlmZnWt6YPARweZmXWv6YPgrCsXdvu41xwys6Jr+iD42+bo9vGZ83wEkZkVW9MHwYSWnfMuwcysrjV9ENz7+cl5l2BmVtcyCwJJV0paI+mxLh4/XdLi9Ot+SYdmVYuZmXUtyx7B1cCUbh7/A3BMREwC/hmYnWEtZmbWhcyWmIiI+ySN7+bx+0vuPgCMzaoWMzPrWr3MEXwcmNfVg5LOkdQuqX3t2rUD/sPHz5g74K9pZtYocg8CSe8hCYILutonImZHRFtEtLW2tvb6Z6yaeUI/KjQza265rj4qaRJwBTA1Ip7NsxYzs6LKrUcgaR/gJuCjEfH7vOowMyu6zHoEkuYAk4EWSR3ApcAQgIiYBXwJ2B34viSATRHRllU9ZmZWWZZHDZ3aw+NnA2dn9fPNzKw6uU8W1wtfttLMiqowQdDTkUPPvbqxRpWYmdWXwgSBmZlV5iAwMys4B4GZWcE5CEr4amVmVkQOghK+WpmZFVGhgmDG1IPzLsHMrO4UKgimHzMx7xLMzOpOoYLAzMy25yAwMys4B0EZLzVhZkXjICjjpSbMrGgKFwS+WpmZ2bYKFwRmZrYtB4GZWcE5CCrwUhNmViQOggq81ISZFUkhg2BCy855l2BmVjcKGQT3fn5y3iWYmdWNQgaBmZm9zkHQBU8Ym1lROAi64AljMysKB4GZWcEVNgi81ISZWaKwQWBmZgkHgZlZwTkIujF+xty8SzAzy5yDwMys4AodBJ4wNjMreBCYmZmDoEfHfn1+3iWYmWXKQdCDlevW512CmVmmHARmZgVX+CDwhLGZFV3hg8DMrOgcBFWYcKFPLDOz5pVZEEi6UtIaSY918bgkfUfSckmLJR2eVS39tSXyrsDMLDtZ9giuBqZ08/hU4ID06xzgBxnWYmZmXcgsCCLiPuC5bnY5CfhxJB4AdpG0V1b1dMcTxmZWZHnOEYwBni6535FuMzOzGsozCFRhW8XReEnnSGqX1L527dqMy6rMK5GaWbPKMwg6gHEl98cCqyvtGBGzI6ItItpaW1trUpyZWVHkGQS3AB9Ljx46CngxIv6cVzGeJzCzohqc1QtLmgNMBlokdQCXAkMAImIWcBtwPLAceBU4K6tazMysa5kFQUSc2sPjAXw6q5+fhfEz5rrnYGZNx2cWm5kVnIPAzKzgHAQlPOxjZkXkIOil/S+6Le8SzMwGlIOglzZ5BTozazIOAjOzgnMQlPE8gZkVjYOgD7zukJk1EweBmVnBOQjMzArOQVDBjKkH512CmVnNVBUEkn4u6QRJhQiO6cdM7HEfzxOYWbOo9g/7D4DTgCclzZTkj8xmZk2iqiCIiLsj4nTgcGAVcJek+yWdJWlIlgWamVm2qh7qkbQ7MA04G3gY+DZJMNyVSWU58/kEZlYU1c4R3AT8BhgOvC8i3h8R10fEecCILAusZ54nMLNmUO2Fab4bEfdWeiAi2gawHjMzq7Fqh4beKGmXzjuSdpX0qWxKMjOzWqo2CD4RES903omI54FPZFJRHalmnuDwy++sQSVmZtmpNgh2kKTOO5IGATtmU1Jjee7VjXmXYGbWL9XOEdwB3CBpFhDAdOD2zKoyM7OaqTYILgD+J/BJQMCdwBVZFWVmZrVT7QllWyLiBxHxwYj4x4j4YURszrq4elDNPIEPIzWzRlZVj0DSAcBXgUOAYZ3bI2JCRnWZmVmNVDtZfBXJekObgPcAPwauyaooMzOrnWqDYKeIuAdQRDwVEZcBx2ZXVn0ZvIN63GfChR4eMrPGVG0QbEiXoH5S0rmSTgb2yLCuurL8X4/vcZ8tUYNCzMwyUG0QfJZknaF/Ao4AzgDOzKgmMzOroR6DID157MMR8UpEdETEWemRQw/UoL6GMmvBirxLMDPrtR6DID1M9IjSM4uLqJrDSGfOW1qDSszMBla1J5Q9DNws6UZgfefGiLgpk6rMzKxmqp0j2A14luRIofelXydmVVQj8/CQmTUaRTTW4S5tbW3R3t6e28+v5ixiX93MzOqNpEVdXT+m2jOLryJZbG4bEfE/+lmbmZnlrNqhoVuBuenXPcAo4JWsimp0065amHcJZmZVq6pHEBE/L70vaQ5wdyYV1bkd1PPJY/OXra1NMWZmA6DaHkG5A4B9BrKQRrHyqx7/N7PmUu0cwctsO0fwDMk1CszMrMFVez2CkRExquTrwPLhokokTZG0TNJySTMqPD5a0q8kPSppiaSz+tKIeuRrFJhZo6gqCCSdLGl0yf1dJP1DD88ZBHwPmEpyHYNTJR1Sttungccj4lBgMvANSXV/LWQfHmpmzaTaOYJLI+LFzjsR8QJwaQ/PORJYHhErI+I14DrgpLJ9AhiZLl8xAniO5JoHTcFLU5tZI6g2CCrt19P8whjg6ZL7Hem2Ut8F3gisBn4HfCYitpS/kKRzJLVLal+7tnGOyPHS1GbWCKoNgnZJ35Q0UdIESf8OLOrhOZUWqSv/03gc8AiwN3AY8F1Jo7Z7UsTsiGiLiLbW1tYqS86Wh4fMrFlUGwTnAa8B1wM3AH8lGd/vTgcwruT+WJJP/qXOAm6KxHLgD8DBVdbUEDxpbGb1rtoTytYD2x3104MHgQMk7Qf8CTgFOK1snz8C7wV+I2lP4CBgZS9/jpmZ9UO1Rw3dJWmXkvu7Srqju+dExCbgXOAO4AnghohYImm6pOnpbv8MHC3pdyRLV1wQEev60I5ceHjIzJpBtdcjaEmPFAIgIp6X1OM1iyPiNuC2sm2zSm6vBv6+yhoa1vgZcx0aZla3qp0j2CJp65ISksZTYTXSIpoxtammNMysgKoNgi8Cv5V0jaRrgAXAhdmV1TimHzOxqv08aWxm9arayeLbJbUB55Ac7nkzyZFDZmbW4KqdLD6bZDL3/PTrGuCy7MpqLB7/N7NGVu3Q0GeAtwJPRcR7gLcAjXOKb53w8JCZ1aNqg2BDRGwAkDQ0IpaSHPNvZmYNrtog6EjPI/glcJekm9n+LOFCq3Z4yL0CM6s31U4Wn5zevEzSr4HRwO2ZVWVmZjXT60tVRsSCiLglXVraSrhXYGaNqK/XLDYzsybhIMjJtKsW5l2CmRngIBhw1Q4PzV/mo2/NrD44CMzMCs5BkAFPGptZI3EQmJkVnIMgI+4VmFmjcBCYmRWcgyBDuw0fUtV+7hWYWZ4cBBl66EtNfxVOM2sCDoI64V6BmeXFQZCx3ly05tivz8+uEDOzLjgI6sjKdevzLsHMCshBUAO96RV4iMjMas1BYGZWcA6CGnGvwMzqlYOghtSLfb1MtZnVioOghv7Qi16Bl6k2s1pxENTYjKkHV72vh4jMrBYcBDU2/ZiJeZdgZrYNB0EOPHFsZvXEQdAAHAZmliUHQU560yswM8uSg6BBuFdgZllxEOSot70Ch4GZZcFBkDOHgZnlzUFgZlZwDoI64F6BmeUp0yCQNEXSMknLJc3oYp/Jkh6RtETSgizrqWcOAzPLS2ZBIGkQ8D1gKnAIcKqkQ8r22QX4PvD+iHgT8KGs6mlGDgMzGwhZ9giOBJZHxMqIeA24DjipbJ/TgJsi4o8AEbEmw3rqXl/OLXAYmFl/ZRkEY4CnS+53pNtKHQjsKmm+pEWSPlbphSSdI6ldUvvatc29KmdfwmDChQ4DM+u7LIOg0vL7UXZ/MHAEcAJwHHCJpAO3e1LE7Ihoi4i21tbWga+0zvQ2DLYEzFqwIqNqzKzZDc7wtTuAcSX3xwKrK+yzLiLWA+sl3QccCvw+w7qa0sx5SwGvbmpmvZdlj+BB4ABJ+0naETgFuKVsn5uBd0kaLGk48DbgiQxrahh9GSKaOW+pewZm1muZBUFEbALOBe4g+eN+Q0QskTRd0vR0nyeA24HFwELgioh4LKuaGk1fw8DMrDcUUT5sX9/a2tqivb097zJqqi9HBnl1UzMrJWlRRLRVesxnFjeAvh5WeuzX5w98MWbWdBwETWzluvXsf9FteZdhZnXOQdAg+jrUs2lL+KQzM+uWg6CB9Gfc32FgZl1xEDSY/oaBDy81s3IOggbUnzCYOW8pb7xk3gBWY2aNzkHQoPoTBn/duMVDRWa2lYOggfX3XIHxM+Yy7aqFA1SNmTUqB0GD628YzF+21r0Ds4JzEDSBVTNPYMbUg/v1GuNnzPVy1mYF5SBoEtOPmdjv3sGW8GGmZkXkIGgyA7HG0PgZcx0IZgXiIGhCA7XgXGcg+NwDs+bmIGhSq2aewOSDBuZqbjPnLXUPwayJeRnqAhjoP+Je4tqs8XgZ6oJbNfOEiheQ7qvOISMvc23WHNwjKJgshnh2EKz8qnsJZvWsux6Bg6CgshrzF3DB1IOZfszETF7fzPrGQ0O2nazG+YPXJ5e9fIVZY3CPwGpyRNBeo4Zx5jvGu6dglhMPDVlVanmI6AwPH5nVlIPAeiWPcwZOPXIc++6+s8PBLCMOAuuTPE8im9CyM/d+fnJuP9+s2TgIrF8Ov/xOnnt1Y95lAD6ZzayvHAQ2YOptqYnOw1UnjR3N4o4XPbRk1gUHgWWi3kKhkt2GD2Hc7sOZ+ua9HBJWaA4Cy9SsBSuYOW9p3mX02eSDWrn6rCMBuH/FOvcsrCk5CKymGqGn0Bc7DhLvPKCFLcHW4DBrFA4Cy009TTTX0g6CiORM692GD2HSuF24+qwj3eOw3DgIrG40a28hS4MEw4cOZtPmLRz8hpEsfeZl9t5lJ47cb7et5144YKwnDgKrW40+v9Bsdhy8A69t2gLAyGFJ+Ow0ZBBKezjHvfkNAHz1A5O2Psch1BgcBNZQpl21kPnL1uZdhtWhQYItJKHUaeSwwYwcOpiXN2xkj1HD6Hj+VTZuDiYf1MqV05LhuF89upq/vLShqvmdWQtWMGnsaI6e2LJ1WzOEnYPAmoIDwopOJPNPm6P363U5CKypTbtqIff9fi1bGuufslm/9eZM++6CYPCAVWSWk2oO5XRvwqxrDgIrhGrCYtaCFTz17HrmLHy6BhWZ9c9bxo0esNfy0JBZP8xasILv/Xo5L2/YlHcpViD7t+7M3edP7tVzPDRklpHpx0zs85EknUenzL5vJYs7XmDj5mDDa5vZ6MkO68Hyteu5f8W6bY5s6o9MewSSpgDfBgYBV0TEzC72eyvwAPCRiPhZd6/pHoFZ9zoDZnHHizz17Hred+jeTLvqQTZvCSLCk+pNpO4niyUNAr4H/HegA3hQ0i0R8XiF/b4G3JFVLWZF0tlDKf20+Pt/mZpLLaWh9KP7V7HnqKG8vGETTz37KjvtOIiRQwez+sUNudRmr8tyaOhIYHlErASQdB1wEvB42X7nAT8H3pphLWaWg9JQauSTscqVBlzn94V/eJY9Rw3j8T+/xCsbNrHv7sN56tlXGTFsMI8+/SIChpScud1fOw3ZYUBeB7INgjFA6eEXHcDbSneQNAY4GTiWboJA0jnAOQD77LPPgBdqZtYb5b2uRg+6gYuU7anCtvLRyW8BF0TE5u5eKCJmR0RbRLS1trYOVH1mZka2PYIOYFzJ/bHA6rJ92oDrJAG0AMdL2hQRv8ywLjMzK5FlEDwIHCBpP+BPwCnAaaU7RMR+nbclXQ3c6hAwM6utzIIgIjZJOpfkaKBBwJURsUTS9PTxWVn9bDMzq16mJ5RFxG3AbWXbKgZAREzLshYzM6us4ZaYkLQWeKqPT28B1g1gOY3AbS4Gt7kY+tPmfSOi4tE2DRcE/SGpvasz65qV21wMbnMxZNXmLA8fNTOzBuAgMDMruKIFwey8C8iB21wMbnMxZNLmQs0RmJnZ9orWIzAzszIOAjOzgitMEEiaImmZpOWSZuRdT29IulLSGkmPlWzbTdJdkp5Mv+9a8tiFaTuXSTquZPsRkn6XPvYdpYs8SRoq6fp0+39KGl/TBlYgaZykX0t6QtISSZ9JtzdtuyUNk7RQ0qNpm7+cbm/aNqc1DZL0sKRb0/tN3V4ASavSeh+R1J5uy6/dEdH0XyRLXKwAJgA7Ao8Ch+RdVy/qfzdwOPBYybZ/A2akt2cAX0tvH5K2byiwX9ruQeljC4G3k6wMOw+Ymm7/FDArvX0KcH0dtHkv4PD09kjg92nbmrbdaX0j0ttDgP8EjmrmNqd1fA64lmStsab/t53WsgpoKduWW7tzf0Nq9Ka/Hbij5P6FwIV519XLNoxn2yBYBuyV3t4LWFapbSRrPb093WdpyfZTgR+W7pPeHkxy5qLybnNZ+28mudpdIdoNDAceIrmGR9O2mWRV4ntIrknSGQRN296SGlexfRDk1u6iDA1VukjOmJxqGSh7RsSfAdLve6Tbu2rrmPR2+fZtnhMRm4AXgd0zq7yX0m7tW0g+ITd1u9NhkkeANcBdEdHsbf4W8AWg9LJdzdzeTgHcKWmRkgtvQY7tznTRuTpSzUVymkVXbe3uPajb90fSCJJLmX42Il5Kh0Ar7lphW8O1O5KLNB0maRfgF5Le3M3uDd1mSScCayJikaTJ1TylwraGaW+Zd0TEakl7AHdJWtrNvpm3uyg9gmouktNo/iJpL4D0+5p0e1dt7Uhvl2/f5jmSBgOjgecyq7xKkoaQhMBPI+KmdHPTtxsgIl4A5gNTaN42vwN4v6RVwHXAsZJ+QvO2d6uIWJ1+XwP8guQa77m1uyhBsPUiOZJ2JJk8uSXnmvrrFuDM9PaZJGPondtPSY8a2A84AFiYdjVflnRUemTBx8qe0/laHwTujXRwMS9pjf8BPBER3yx5qGnbLak17QkgaSfg74ClNGmbI+LCiBgbEeNJ/k/eGxFn0KTt7SRpZ0kjO28Dfw88Rp7tznvSpIaTM8eTHHmyAvhi3vX0svY5wJ+BjSRJ/3GS8b57gCfT77uV7P/FtJ3LSI8iSLe3pf/gVgDf5fUzy4cBNwLLSY5CmFAHbX4nSVd2MfBI+nV8M7cbmAQ8nLb5MeBL6fambXNJvZN5fbK4qdtLcvTio+nXks6/R3m220tMmJkVXFGGhszMrAsOAjOzgnMQmJkVnIPAzKzgHARmZgXnIDCrIUmTO1fZNKsXDgIzs4JzEJhVIOkMJdcGeETSD9PF4F6R9A1JD0m6R1Jruu9hkh6QtFjSLzrXkZe0v6S7lVxf4CFJE9OXHyHpZ5KWSvpp5xryZnlxEJiVkfRG4CMkC4MdBmwGTgd2Bh6KiMOBBcCl6VN+DFwQEZOA35Vs/ynwvYg4FDia5OxwSFZS/SzJOvMTSNbcMctNUVYfNeuN9wJHAA+mH9Z3IlkAbAtwfbrPT4CbJI0GdomIBen2HwE3pmvJjImIXwBExAaA9PUWRkRHev8RkmtN/DbzVpl1wUFgtj0BP4qIC7fZKF1Stl9367N0N9zzt5Lbm/H/Q8uZh4bMtncP8MF0rfjOa8nuS/L/5YPpPqcBv42IF4HnJb0r3f5RYEFEvAR0SPqH9DWGShpey0aYVcufRMzKRMTjki4muYLUDiSrvn4aWA+8SdIikis+fSR9ypnArPQP/UrgrHT7R4EfSro8fY0P1bAZZlXz6qNmVZL0SkSMyLsOs4HmoSEzs4Jzj8DMrODcIzAzKzgHgZlZwTkIzMwKzkFgZlZwDgIzs4L7L/B/rYCHU2uhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracies = [result['val_loss'] for result in history]\n",
    "plt.plot(accuracies, '-x')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('loss vs. No. of epochs');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77090552",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
