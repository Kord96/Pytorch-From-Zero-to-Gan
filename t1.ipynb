{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2fa8767",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0cde311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t4 = torch.tensor([\n",
    "    [[11, 12, 13], \n",
    "     [13, 14, 15]], \n",
    "    [[15, 16, 17], \n",
    "     [17, 18, 19.]]])\n",
    "t4.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c8fdf13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([15., 16., 17.])\n",
      "tensor([15., 16., 17.])\n"
     ]
    }
   ],
   "source": [
    "#In case of 3D: first index is to choose which slice/matrix/depth. The other two are row/column for this slice.\n",
    "#note: you can't get a column by indexing twice\n",
    "print(t4[1][0])\n",
    "print(t4[1][:][0]) #same as the previous line. It means choose all rows in the matrix then choose the row 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b8402ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 3 at dim 1 (got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_62587/304844875.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Matrix: Note that it's not possible to create tensors with an improper shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m t5 = torch.tensor([[5., 6, 11], \n\u001b[0m\u001b[1;32m      4\u001b[0m                    \u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                    [9, 10]])\n",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 3 at dim 1 (got 2)"
     ]
    }
   ],
   "source": [
    "# Matrix: Note that it's not possible to create tensors with an improper shape.\n",
    "\n",
    "t5 = torch.tensor([[5., 6, 11], \n",
    "                   [7, 8], \n",
    "                   [9, 10]])\n",
    "t5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe85c13",
   "metadata": {},
   "source": [
    "# autograd (automatic gradients).\n",
    "1. If you have an output y that is function of tensors with .tensor(val,requires_grad=True). The gradients of these tensors will automatically update when you do y.backward()\n",
    "2. if you have multiple outputs (e.g. y2 and y22) and they are functions of the same tensors, tensor.grad would hold the sum of all gradients.\n",
    "3. to find the gradient w.r.t a specific output, you need to use torch.autograd.grad(func,tens)\n",
    "4. To reduce memory usage, during the .backward() call, all the intermediary results are deleted when they are not needed anymore. Hence if you try to call .backward() twice, you have to .backward(retain_graph=True ) .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2b098419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy/dx: None\n",
      "dy/dw: tensor(3.)\n",
      "dy/db: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# Create tensors.\n",
    "x = torch.tensor(3.)\n",
    "w = torch.tensor(4., requires_grad=True)\n",
    "b = torch.tensor(5., requires_grad=True)\n",
    "\n",
    "# Arithmetic operations\n",
    "y = w * x + b\n",
    "\n",
    "y.backward()\n",
    "\n",
    "# Display gradients\n",
    "print('dy/dx:', x.grad)\n",
    "print('dy/dw:', w.grad)\n",
    "print('dy/db:', b.grad)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7a4bdcf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy/dx: None\n",
      "dy/dw: None\n",
      "dy/db: None\n"
     ]
    }
   ],
   "source": [
    "#here we don't call .backward hence no grads\n",
    "# Create tensors.\n",
    "x1 = torch.tensor(3.)\n",
    "w1 = torch.tensor(4., requires_grad=True)\n",
    "b1 = torch.tensor(5., requires_grad=True)\n",
    "\n",
    "# Arithmetic operations\n",
    "y1 = w1 * x1 + b1\n",
    "\n",
    "# Display gradients\n",
    "print('dy/dx:', x1.grad)\n",
    "print('dy/dw:', w1.grad)\n",
    "print('dy/db:', b1.grad)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2e1698f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy/dx: tensor(28.)\n",
      "dy/dw: tensor(12.)\n",
      "dy/db: tensor(2.)\n",
      "\n",
      "dy/dx decomposed:\n",
      "\n",
      "dy2/dx: (tensor(4.),)\n",
      "dy22/dx: (tensor(24.),)\n"
     ]
    }
   ],
   "source": [
    "#here we do multiple calls of .backward\n",
    "# Create tensors.\n",
    "x2 = torch.tensor(3.,requires_grad=True)\n",
    "w2 = torch.tensor(4., requires_grad=True)\n",
    "b2 = torch.tensor(5., requires_grad=True)\n",
    "\n",
    "# Arithmetic operations\n",
    "y2 = w2 * x2 + b2\n",
    "y22 = w2*x2*x2 + b2 #random operation just to test the effect on x.grad\n",
    "\n",
    "y2.backward(retain_graph=True )\n",
    "y22.backward(retain_graph=True )\n",
    "# Display gradients\n",
    "print('dy/dx:', x2.grad)\n",
    "print('dy/dw:', w2.grad)\n",
    "print('dy/db:', b2.grad)\n",
    "\n",
    "print(\"\\ndy/dx decomposed:\\n\")\n",
    "print('dy2/dx:', torch.autograd.grad(y2,x2))\n",
    "print('dy22/dx:', torch.autograd.grad(y22,x2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c4ccf44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 2])\n",
      "torch.Size([3, 2]) torch.Size([3, 2]) torch.Size([6, 2])\n",
      "tensor([[ 5.,  6.],\n",
      "        [ 7.,  8.],\n",
      "        [ 9., 10.],\n",
      "        [42., 42.],\n",
      "        [42., 42.],\n",
      "        [42., 42.]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor([[5., 6], \n",
    "                   [7, 8], \n",
    "                   [9, 10]])\n",
    "\n",
    "print(t3.shape)\n",
    "\n",
    "t2 = torch.full((3, 2), 42) #creates a tensor with fixed val\n",
    "t3 = torch.cat((t1, t2)) #concat\n",
    "\n",
    "\n",
    "print(t1.shape, t2.shape, t3.shape)\n",
    "print(t3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "96ee4b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[42, 42],\n",
      "        [42, 42],\n",
      "        [42, 42]]) \n",
      "\n",
      " tensor([[[42],\n",
      "         [42]],\n",
      "\n",
      "        [[42],\n",
      "         [42]],\n",
      "\n",
      "        [[42],\n",
      "         [42]]])\n",
      "\n",
      "\n",
      " although comparison gives true, one dim is not the same as 1 dim\n",
      "\n",
      "\n",
      "tensor([42, 42])\n",
      "tensor([[42],\n",
      "        [42]])\n",
      "tensor([[True, True],\n",
      "        [True, True]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Tensors must have same number of dimensions: got 1 and 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_62587/3815537012.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mt2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mt3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mt3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 1 and 2"
     ]
    }
   ],
   "source": [
    "t1 = torch.full((3, 2), 42)\n",
    "t2 = torch.full((3, 2,1), 42)\n",
    "print(t1,'\\n\\n',t2)\n",
    "print(\"\\n\\n although comparison gives true, one dim is not the same as 1 dim\\n\\n\")\n",
    "print(t1[0])\n",
    "print(t2[0])\n",
    "print(t1[0] == t2[0])\n",
    "\n",
    "t3 = torch.cat((t1[0], t2[0])) #error\n",
    "t3 = torch.cat((t1, t2)) #error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619aec27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
